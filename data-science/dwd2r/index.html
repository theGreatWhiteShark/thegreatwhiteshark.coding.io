<!DOCTYPE html>
<html lang="en-us">
<head>

    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    
    
        <meta name="twitter:card" content="summary"/>
    



<meta name="twitter:title" content="dwd2r"/>
<meta name="twitter:description" content="The one thing a data scientist is needing most is, of course, data itself. Vast and well-formatted data. If you are interested in climatological one from Germany, the DWD will provide you with tons of files by the means of their [FTP server](http://ftp-cdc.dwd.de/). To ease the task of downloading, importing, and converting all the data into **R**, I wrote a package called [dwd2r](https://github.com/theGreatWhiteShark/dwd2r)."/>
<meta name="twitter:site" content="@"/>



  	<meta property="og:title" content="dwd2r" />
  	<meta property="og:site_name" content="theGreatWhiteShark" />
  	<meta property="og:url" content="https://thegreatwhiteshark.github.io/thegreatwhiteshark.coding.io/data-science/dwd2r/" />

    
        
            <meta property="og:image" content="/thegreatwhiteshark.coding.io/images/moses-banner.png"/>
        
    

    
    <meta property="og:description" content="The one thing a data scientist is needing most is, of course, data itself. Vast and well-formatted data. If you are interested in climatological one from Germany, the DWD will provide you with tons of files by the means of their [FTP server](http://ftp-cdc.dwd.de/). To ease the task of downloading, importing, and converting all the data into **R**, I wrote a package called [dwd2r](https://github.com/theGreatWhiteShark/dwd2r)." />
  	<meta property="og:type" content="article" />
    <meta property="article:published_time" content="2018-11-28T12:44:15&#43;01:00" />

    
    <meta property="article:tag" content="R" />
    
    <meta property="article:tag" content="data science" />
    
    

    <title>dwd2r</title>

    
    <meta name="description" content="The one thing a data scientist is needing most is, of course, data itself. Vast and well-formatted data. If you are interested in climatological one from Germany, the DWD will provide you with tons of files by the means of their [FTP server](http://ftp-cdc.dwd.de/). To ease the task of downloading, importing, and converting all the data into **R**, I wrote a package called [dwd2r](https://github.com/theGreatWhiteShark/dwd2r)." />
    

    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="shortcut icon" href="/thegreatwhiteshark.coding.io/images/favicon.ico">
	  <link rel="apple-touch-icon" href="/thegreatwhiteshark.coding.io/images/apple-touch-icon.png" />

    <link rel="stylesheet" type="text/css" href="/thegreatwhiteshark.coding.io/css/screen.css" />
    <link rel="stylesheet" type="text/css" href="/thegreatwhiteshark.coding.io/css/nav.css" />
    <link rel="stylesheet" type="text/css" href="/thegreatwhiteshark.coding.io/css/custom.css" />

    

    

    
      
          <link href="/thegreatwhiteshark.coding.io/index.xml" rel="alternate" type="application/rss+xml" title="theGreatWhiteShark" />
      
      
    
    <meta name="generator" content="Hugo 0.32.2" />

    <link rel="canonical" href="https://thegreatwhiteshark.github.io/thegreatwhiteshark.coding.io/data-science/dwd2r/" />

    
      
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": 
    },
    "author": {
        "@type": "Person",
        "name": ,
        
        "url": https://thegreatwhiteshark.github.io/,
        "sameAs": [
            
            
             
             
             
             
             
            
        ]
    },
    "headline": dwd2r,
    "name": dwd2r,
    "wordCount": 1185,
    "timeRequired": "PT6M",
    "inLanguage": {
      "@type": "Language",
      "alternateName": en
    },
    "url": https://thegreatwhiteshark.github.io/thegreatwhiteshark.coding.io/data-science/dwd2r/,
    "datePublished": 2018-11-28T12:44Z,
    "dateModified": 2018-11-28T12:44Z,
    
    "keywords": R, data science,
    "description": The one thing a data scientist is needing most is, of course, data itself. Vast and well-formatted data. If you are interested in climatological one from Germany, the DWD will provide you with tons of files by the means of their [FTP server](http://ftp-cdc.dwd.de/). To ease the task of downloading, importing, and converting all the data into **R**, I wrote a package called [dwd2r](https://github.com/theGreatWhiteShark/dwd2r).,
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": https://thegreatwhiteshark.github.io/thegreatwhiteshark.coding.io/data-science/dwd2r/
    }
}
    </script>
    


    

    

    
</head>
<body class="nav-closed">

  <div class="nav">
    <h3 class="nav-title">Menu</h3>
    <a href="#" class="nav-close">
        <span class="hidden">Close</span>
    </a>
    <ul>
        
        
        
            
            <li class="nav-opened" role="presentation">
            	<a href="/thegreatwhiteshark.coding.io/">Home</a>
            </li>
        
            <h3>Topics</h3>
            <li class="nav-opened" role="presentation">
            	<a href="/thegreatwhiteshark.coding.io/data-science">Data Science</a>
            </li>
        
            
            <li class="nav-opened" role="presentation">
            	<a href="/thegreatwhiteshark.coding.io/hacks">Hacks</a>
            </li>
        
            <h3>Follow me</h3>
            <li class="nav-opened" role="presentation">
            	<a href="https://github.com/theGreatWhiteShark">Github repos</a>
            </li>
        
            
            <li class="nav-opened" role="presentation">
            	<a href="https://thegreatwhiteshark.github.io/">Blogs</a>
            </li>
        
            
            <li class="nav-opened" role="presentation">
            	<a href="/thegreatwhiteshark.coding.io/about">About me</a>
            </li>
        
        
    </ul>

    
    <a class="subscribe-button icon-feed" href="/thegreatwhiteshark.coding.io/index.xml">Subscribe</a>
    
</div>
<span class="nav-cover"></span>


 <div class="site-wrapper">



      <header class="main-header post-head no-cover">
	<nav class="main-nav clearfix">
	  

	  
	  
	  <a class="menu-button" href="#"><span class="burger">&#9776;</span><span class="word">Menu</span></a>
	  
	</nav>
      </header>



      <main class="content" role="main">

	<article class="post data-science">

	  <header class="post-header">
	    <h1 class="post-title">dwd2r</h1>
	    
	      <h3 class="post-subtitle">Download and import climatological data sets of the German weather service (DWD)</h3>
	    
	    <hr class="post-description-separator"/>
	    <section class="post-description-single">  
	      <p>The one thing a data scientist is needing most is, of course, data itself. Vast and well-formatted data. If you are interested in climatological one from Germany, the DWD will provide you with tons of files by the means of their <a href="http://ftp-cdc.dwd.de/">FTP server</a>. To ease the task of downloading, importing, and converting all the data into <strong>R</strong>, I wrote a package called <a href="https://github.com/theGreatWhiteShark/dwd2r">dwd2r</a>.
	    </section>
	    <hr class="post-description-separator"/>
            <section class="post-meta">
              
              
              <span class="post-tag small"><a href="https://thegreatwhiteshark.github.io/thegreatwhiteshark.coding.io//tags/r/">#R</a></span>
              
              <span class="post-tag small"><a href="https://thegreatwhiteshark.github.io/thegreatwhiteshark.coding.io//tags/data-science/">#data science</a></span>
              
            </section>
	  </header>

	  <section class="post-content">
	    

<p>The German weather service (DWD) provides a large set of
climatological data under the following <a href="ftp://ftp-cdc.dwd.de/pub/CDC/Terms_of_use.txt">terms of
use</a>. This is an
awesome starting point for data-driven software or research. But, as
usual, it is only the starting point. The observational data itself is
provided for all individual stations in separate files and split into
the most recent and a historical part. This is of course quite
convenient in case you want to update your data sets but it&rsquo;s up to
the user to combine both parts for each and every station. Once again,
the retrieval, cleaning, and conversion of the data will take up a
significant portion of our time.</p>

<p>To ease or even overcome the burden of downloading all the different
station data, to import them into <strong>R</strong>, and to convert them into an
usable format, I wrote the software package
<a href="https://github.com/theGreatWhiteShark/dwd2r">dwd2r</a>.</p>

<h2 id="installation">Installation</h2>

<p>To install the package, you have to clone the repository using a
command line/terminal,</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">git clone https://gitlab.com/theGreatWhiteShark/dwd2r</code></pre></div>
<p>open a <strong>R</strong> shell in the newly created folder,</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">cd dwd2r
R</code></pre></div>
<p>and install the package using <code>devtools</code>.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-R" data-lang="R">devtools<span style="color:#f92672">::</span>install()</code></pre></div>
<h2 id="features-and-usage">Features and usage</h2>

<h4 id="convenient-interface-to-the-ftp-server">Convenient interface to the FTP server</h4>

<p>First of all, the user has to decide which data to download from the
FTP server. This can be done (inside <strong>R</strong>) in two different ways. Per
default a command line user interface will guide the user through the
hierarchy of the FTP server, prints the folder structure of the
current level into the <strong>R</strong> shell, and prompts for a selection of one of
those options. All data located in the selected terminal node will be
downloaded afterwards.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-R" data-lang="R">dwd.download()</code></pre></div>
<p>You also can circumvent the user interface and provide all the choices
you would select via the input argument <code>batch.choices</code>. The following
call will, e.g., download the aggregated, daily observation data
throughout German.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-R" data-lang="R">dwd.download( batch.choices <span style="color:#f92672">=</span> <span style="color:#66d9ef">c</span>( <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">1</span> ) )</code></pre></div>
<p>As a second way, you can use the listing of all folders on the FTP
server returned by the <code>dwd2r:::cat.dwd.ftp.url()</code> function and use
commands like <code>grep()</code> to select only the URLs you are interested
in. These can be provided to the <code>dwd.download()</code> function using the
<code>url</code> input argument. This code snippet will download the same data as
the former one.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-R" data-lang="R">dwd.download( 
  url <span style="color:#f92672">=</span> <span style="color:#66d9ef">grep</span>( <span style="color:#e6db74">&#34;daily/kl&#34;</span>, 
              dwd2r<span style="color:#f92672">:::</span>cat.dwd.ftp.url()<span style="color:#f92672">$</span>observations.germany,
              value<span style="color:#f92672">=</span><span style="color:#66d9ef">TRUE</span> ) )</code></pre></div>
<p>After downloading the selected data the <code>dwd.download()</code> function will
handle its conversion internally and stores the results in <em>.RData</em>
files.</p>

<h4 id="what-does-the-downloaded-data-looks-like">What does the downloaded data looks like?</h4>

<p>For the choices made in the last section a large set of <em>.zip</em>
archives will be downloaded with each of them containing one table
holding the aggregated data for either the recent or the historical
part of the measurements performed at a single station. Aggregate
means we have about 17 columns with one corresponding to the time and
date of the measurement and the others to different climatological
quantities. To obtain, e.g., the daily accumulated precipitation data
of a single station, one first has to look up the ID of the station,
find both the historical and recent archive containing its data, and,
finally, extract the data from the right columns and join them
together.</p>

<h4 id="what-does-the-final-data-looks-like">What does the final data looks like?</h4>

<p>The <strong>dwd2r</strong> package will split the aggregated data into different
lists named according to the corresponding quantity. E.g,
<em>dwd.temperature.2m.max</em> will contain the daily maximum temperature
measurements taken two meters above the ground. The lists contain
separate entries for each station and are named accordingly. The
elements, or the actual measurements, contain both the historical and
recent part of the series, are ordered properly, and can be provided
in two different formats. Per default
<a href="https://github.com/joshuaulrich/xts">xts</a>-class objects will be
generated. But the user can also choose to have <em>data.frame</em>-class
objects by setting the <code>time.series.format</code> input argument of
<code>dwd.download()</code> to <code>&quot;data.frame&quot;</code>. These data frames will contain two
columns: <em>date</em>, of class <em>Date</em> holding the individual dates of the
observations, and <em>value</em>, of class <em>numeric</em> holding the actual
measurements.</p>

<p>Along with these lists an addition object containing the geographic
metadata of the stations will be generated as well. It will either be
a <em>SpatialPointsDataFrame</em> provided by the
<a href="https://github.com/edzer/sp/">sp</a> package (default) or a <em>data.frame</em>
when setting the <code>use.geospatial.position.format</code> input argument of
<code>dwd.download()</code> to <code>FALSE</code>. Each row of this object will contain the
longitude, latitude, altitude, and the corresponding name of a
single station.</p>

<p>For each climatological quantity a separate <em>.RData</em> file will be
generated containing both the list holding the measured data as well
as the metadata object.</p>

<h4 id="customization">Customization</h4>

<p>Per default all data will be stored in the <em>R/dwd_data</em> directory in
your home. If you want to change this behavior, you can hand over a
string specifying the path to your favored destination using the
<code>download.folder</code> argument of the <code>dwd.download()</code> function.</p>

<p>As an alternative you can also overwrite the global option <strong>dwd2r</strong>
uses to store its download path in. Just add the following line to
the <em>.Rprofile</em> file in your home directory.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-R" data-lang="R"><span style="color:#66d9ef">options</span>( dwd2r.download.path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;PATH&#34;</span> )</code></pre></div>
<p>All downloads will now be stored in the <em>PATH</em> directory.</p>

<h4 id="loading-the-converted-data">Loading the converted data</h4>

<p>Since <code>dwd.download()</code> might generate quite a bunch of data files and
the user might already have a lot of them on her machine, the
<strong>dwd2r</strong> package ships with the helper function <code>source.data()</code>. It
lists all <em>.RData</em> files including their size found in the folder the
global option <code>dwd2r.download.path</code> is pointing to.</p>

<h4 id="additional-features">Additional features</h4>

<p>The <code>dwd.download()</code> function is also able to export all station data
into <em>.csv</em> files. You might wonder why this would be a benefit
compared to the data set provided by the FTP server. For one, the
recent and historical part of the series are already combined. Also
the DWD uses a value of <code>-999</code> for missing data points, which will be
replaced by the more <strong>R</strong>-friendly <code>NA</code> values and the date format is
less obscure.</p>

<p>Another very important aspect of the <code>dwd.download()</code> function is that
it stored the downloaded <em>.zip</em> archives (per default) and only
downloads those files during future calls who&rsquo;s time stamps have
changed. This way you can very easily update your data set without
downloading the whole content anew.</p>

<h2 id="known-bugs-and-issues">Known bugs and issues</h2>

<p>For now the internal functions handling the conversion of the data
have been only tested for the particular choice of data presented in
the code snippets earlier on. It might fail with a different set of
choices. But supporting another format is not a big deal and even if I
don&rsquo;t find myself in need to implemented it, do not hesitate to open
an issue to ask for it.</p>

<p>Also when you run the tests using <code>devtools::test()</code> you sometimes
receive errors like &ldquo;URL could not be found on server&rdquo; or
similar. This is not a real bug in the code but is caused by the
server of the DWD itself. It has some measures to detect bots and
blocking their IP address for some seconds. I already implemented some
counter measures and most of the time we can download huge sets of
data from the server without it noticing. But every now and then
<strong>dwd2r</strong> gets blocked and you have to wait some 10-20 seconds until
it does work fine again.</p>

	  </section>


	  <footer class="post-footer">


	    




	    
<section class="share">
  <h4>Share this post</h4>
  <a class="icon-twitter" style="font-size: 1.4em" href="https://twitter.com/share?text=dwd2r&nbsp;-&nbsp;theGreatWhiteShark&amp;url=https%3a%2f%2fthegreatwhiteshark.github.io%2fthegreatwhiteshark.coding.io%2fdata-science%2fdwd2r%2f"
      onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
      <span class="hidden">Twitter</span>
  </a>
  <a class="icon-facebook" style="font-size: 1.4em" href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fthegreatwhiteshark.github.io%2fthegreatwhiteshark.coding.io%2fdata-science%2fdwd2r%2f"
      onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
      <span class="hidden">Facebook</span>
  </a>
  <a class="icon-pinterest" style="font-size: 1.4em" href="http://pinterest.com/pin/create/button/?url=https%3a%2f%2fthegreatwhiteshark.github.io%2fthegreatwhiteshark.coding.io%2fdata-science%2fdwd2r%2f&amp;description=dwd2r"
      onclick="window.open(this.href, 'pinterest-share','width=580,height=296');return false;">
      <span class="hidden">Pinterest</span>
  </a>
  <a class="icon-google-plus" style="font-size: 1.4em" href="https://plus.google.com/share?url=https%3a%2f%2fthegreatwhiteshark.github.io%2fthegreatwhiteshark.coding.io%2fdata-science%2fdwd2r%2f"
     onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
      <span class="hidden">Google+</span>
  </a>
</section>



	    

<div id="disqus_thread"></div>
<script>




var disqus_config = function () {
this.page.url = "https:\/\/thegreatwhiteshark.github.io\/thegreatwhiteshark.coding.io\/data-science\/dwd2r\/";  
this.page.identifier = "https:\/\/thegreatwhiteshark.github.io\/thegreatwhiteshark.coding.io\/data-science\/dwd2r\/"; 
};

(function() { 
var d = document, s = d.createElement('script');
s.src = 'https://thegreatwhiteshark-coding-io.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>








	  </footer>
	</article>

      </main>

      
      <aside class="read-next">
  
  
  <a class="read-next-story prev" style="no-cover" href="/thegreatwhiteshark.coding.io/data-science/bundestagswahl-pt-ii/">
    <section class="post">
      <h2>A data scientist’s view on the election for the Bundestag Pt. II</h2>
      
        <h4>Visualizing spatial information in R</h4>
      
    </section>
  </a>
  
</aside>

      

          <footer class="site-footer clearfix">
        <section class="copyright"><a href="">theGreatWhiteShark</a> </section>
        
        <section class="poweredby">Proudly generated by <a class="icon-hugo" href="http://gohugo.io">HUGO</a>, with <a class="icon-theme" href="https://github.com/vjeantet/hugo-theme-casper">Casper</a> theme</section>
        
    </footer>
    </div>
    <script type="text/javascript" src="/thegreatwhiteshark.coding.io/js/jquery.js"></script>
    <script type="text/javascript" src="/thegreatwhiteshark.coding.io/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="/thegreatwhiteshark.coding.io/js/index.js"></script>
    
</body>
</html>

